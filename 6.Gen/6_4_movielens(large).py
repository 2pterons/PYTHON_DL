# -*- coding: utf-8 -*-
"""6-4.movieLens(large).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-XZEB4PG1QKQ7W5rtCFVXHIugPEU3umI
"""

# 영화 추천시스템 (Movie Recommendation System) : 행렬 분해를 이용한 잠재 요인 협업 필터링 사용
# Keras Embedding layer를 적용한다.
import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error
from tensorflow.keras.layers import Input, Dense, Dropout, Embedding
from tensorflow.keras.layers import Flatten, Dot, Activation
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import tensorflow.keras.backend as K
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from datetime import datetime
import time

# Commented out IPython magic to ensure Python compatibility.
# 학습 데이터를 읽어온다.
# %cd '/content/drive/My Drive/Colab Notebooks/'
movies = pd.read_csv('data/MovieLens/movies27.csv')
ratings = pd.read_csv('data/MovieLens/ratings27.csv')

# 데이터가 너무 커서 2010년 이전 영화는 제외한다. 최근 8년간 영화만 추천 대상으로 한다.
# 데이터는 1995.1.9 ~ 2018.9.26 까지 있음.
s_date = '2010-01-01 00:00:00'
timestamp = time.mktime(datetime.strptime(s_date, '%Y-%m-%d %H:%M:%S').timetuple())
ratings = ratings[ratings['timestamp'] > timestamp]

# 100명 이상 평점이 부여된 영화만 사용한다. 많지는 않다.
value_counts = ratings['movieId'].value_counts()
to_remove = value_counts[value_counts <= 100].index
ratings = ratings[~ratings['movieId'].isin(to_remove)]

# 특정 user가 부여한 rating 분포
# sns.displot(ratings[ratings['userId']==13]['rating'])
# plt.xlim(0, 5)
# plt.show()

df = pd.merge(ratings, movies, on='movieId')[['userId', 'movieId', 'rating', 'title']]

# userId와 movieId가 중간에 빈 값이 있을 수 있으므로 순차적인 id를 다시 부여한다.
user_enc = LabelEncoder()
item_enc = LabelEncoder()

df['userId'] = user_enc.fit_transform(df['userId'])
df['movieId'] = item_enc.fit_transform(df['movieId'])
df['rating'] /= 5.0   # 0.5 ~ 5.0 --> 0.1 ~ 1.0으로 표준화.
df.head()

# number of users and items
n_users = df['userId'].max() + 1
n_items = df['movieId'].max() + 1
n_factors = 15

# 학습 데이터와 시험 데이터로 분리
d_train, d_test = train_test_split(df, test_size = 0.1)

# 학습 데이터 세트를 생성한다.
x_user_train = np.array(d_train['userId']).reshape(-1, 1)
x_item_train = np.array(d_train['movieId']).reshape(-1, 1)
y_rating_train = np.array(d_train['rating']).reshape(-1, 1)

# 시험 데이터 세트를 생성한다.
x_user_test = np.array(d_test['userId']).reshape(-1, 1)
x_item_test = np.array(d_test['movieId']).reshape(-1, 1)
y_rating_test = np.array(d_test['rating']).reshape(-1, 1)
x_user_train.shape, x_item_train.shape

# 출력이 0 ~ 1로 제한된 경우의 regression 문제에 적합한 loss function은 무엇인가?
def bounded_activation(x):
    # return K.sigmoid(x)
    # return K.hard_sigmoid(x)
    # return K.clip(x, 0, 1.0)
    return x    # linear activation

x_input_user = Input(batch_shape = (None, x_user_train.shape[1]))
x_input_item = Input(batch_shape = (None, x_item_train.shape[1]))

x_user_emb = Embedding(input_dim = n_users, output_dim = n_factors)(x_input_user)
x_user_emb = Dropout(0.5)(x_user_emb)
x_user_emb = Flatten()(x_user_emb)

x_item_emb = Embedding(input_dim = n_items, output_dim = n_factors)(x_input_item)
x_item_emb = Dropout(0.5)(x_item_emb)
x_item_emb = Flatten()(x_item_emb)

y_output = Dot(axes=1)([x_user_emb, x_item_emb])
y_output = Activation(bounded_activation)(y_output)

model = Model([x_input_user, x_input_item], y_output)
model.compile(loss='mse', optimizer = Adam(learning_rate=0.001))
model.summary()

# 학습
hist = model.fit([x_user_train, x_item_train], y_rating_train, 
                 batch_size=10240, 
                 epochs = 30,
                 shuffle = True,
                 validation_data=([x_user_test, x_item_test], y_rating_test))

# loss 확인
plt.plot(hist.history['loss'], label='train')
plt.plot(hist.history['val_loss'], label='test')
plt.legend()
plt.show()

# 타겟 유저가 보지 않은 영화들에 대해 해당 유저가 부여할 rating을 추정한다.
user_id = user_enc.transform([13])[0]         # target user = 13
top_n = 20          # 추정 평점이 높은 상위 top_n개 추천

# target user가 본 movieId
seen_id = set(df[df['userId'] == user_id]['movieId'])

# target user가 보지 않은 movieId
unseen_id = list(set(df['movieId']) - seen_id)

# target user가 보지 않은 영화의 평점을 추정하기 위한 데이터 세트를 생성한다.
x_target_item = np.array(unseen_id, dtype=np.int32)
x_target_user = np.ones(shape = x_target_item.shape, dtype=np.int32) * user_id

# target user가 보지 않은 영화의 평점을 추정한다.
x_target_rating = model.predict([x_target_user, x_target_item])

# 추정 평점이 높은 순서로 정렬한다. 학습시 rating을 5로 나눠주었기 때문에, 다시 5를 곱해주었다.
x_target_df = pd.DataFrame({'userId': user_enc.inverse_transform(x_target_user), 
                            'movieId': item_enc.inverse_transform(x_target_item),
                            'rating': x_target_rating.reshape(-1) * 5})

x_target_df = x_target_df.sort_values(by = 'rating', ascending = False)[:top_n]
x_target_df[['userId', 'movieId']] = x_target_df[['userId', 'movieId']].astype('int64')
x_target_df.head()

# 추천 결과를 출력한다.
print('\n영화 추천 목록 : User = {}'.format(user_enc.inverse_transform([user_id])[0]))
print(" No {:40s} {:s}".format('Title', 'Expected rating'))
for i, (idx, row) in enumerate(x_target_df.iterrows()):
    title = movies[movies['movieId'] == row['movieId']]['title'].values[0]
    print("{:2d} : {:40s}     {:.4f}".format(i+1, title[:39], row['rating']))

# # 평가. MSE로 평가한다.
# # 추천 결과에 대한 신뢰도로 활용할 수 있다.
# pred = model.predict([x_user_test, x_item_test])

# # MSE를 계산한다.
# mse = mean_squared_error(pred, y_rating_test)
# print('MSE =', mse.round(4))

# from sklearn.metrics import r2_score
# r2_score(y_rating_test, pred)

import seaborn as sns
sns.displot(x_target_rating * 5)

